# Install required packages (only for Jupyter/Colab)
%pip install opencv-python-headless
%pip install mediapipe
%pip install matplotlib

# === Import Libraries ===
import cv2
import mediapipe as mp
import matplotlib.pyplot as plt
import numpy as np
import time
from IPython.display import clear_output

# === Initialize MediaPipe Pose ===
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False,
                    min_detection_confidence=0.5,
                    min_tracking_confidence=0.5)
mp_drawing = mp.solutions.drawing_utils

# === Function: Calculate Angle Between 3 Points ===
def calculateAngle(a, b, c):
    a = np.array([a.x, a.y])
    b = np.array([b.x, b.y])
    c = np.array([c.x, c.y])
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180.0 else angle

# === Function: Classify Pose ===
def classifyPose(landmarks, output_image):
    label = 'Unknown Pose'
    color = (0, 0, 255)

    # Calculate relevant joint angles
    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],
                                      landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],
                                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])
    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],
                                         landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],
                                         landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])

    # Pose classification logic
    if 40 < left_elbow_angle < 60 and 15 < left_shoulder_angle < 25:
        label = 'Push-Up Down Position'
    elif 165 < left_elbow_angle < 180 and 70 < left_shoulder_angle < 80:
        label = 'Push-Up Start Position'

    if label != 'Unknown Pose':
        color = (0, 255, 0)

    # Display pose label on the image
    cv2.putText(output_image, label, (10, 30),
                cv2.FONT_HERSHEY_PLAIN, 2, color, 2)

    return output_image, label

# === Webcam Setup ===
cap = cv2.VideoCapture(0)  # Change to 1 if needed

# Initialize push-up logic variables
counter = 0
stage = None

# === Main Loop ===
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Convert frame to RGB for MediaPipe
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image)

    # If pose detected, classify it
    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        frame, label = classifyPose(landmarks, frame)

        # Count repetitions
        if label == 'Push-Up Down Position':
            stage = 'down'
        elif label == 'Push-Up Start Position' and stage == 'down':
            stage = 'up'
            counter += 1

        # Show push-up counter
        cv2.putText(frame, f'Push-Ups: {counter}', (10, 70),
                    cv2.FONT_HERSHEY_TRIPLEX, 1, (255, 255, 0), 2)

    # Display the frame (Jupyter)
    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.show()
    time.sleep(0.02)
    clear_output(wait=True)

# Release the camera
cap.release()
